---
layout: default
title: ORNL's AI Seminar Series <br/> 
description: Organized by  AI Initiative <br/>
             11am - noon ET <br/> 
             Every Other Thursday, January-December, 2025 <br/> 
             Hybrid (Onsite & Virtual) <br/>
             
permalink: /events/ai-initiative-seminar-2025/
tags: events
---

# About

The ORNL AI Seminar Series (Biweekly/Hybrid), organized by the [AI Initiative](https://www.ornl.gov/ai-initiative), serves as a platform for researchers and engineers from diverse scientific, engineering, and national security backgrounds spanning ORNL, universities, and industry.
Our main objective is to encourage collaboration with the goal of driving transformative advancements in safe, trustworthy, and energy-efficient AI research and its applications.

The seminar will be held every other Thursday from 11 am to 12 pm ET.
Please reach out to the organizers if you would like to recommend a spearker or give a talk.

<a href="#top"> &#10558; Back to top</a>

# Next Presentations

**Federal AI Policy Overview**

<br>Location: MS Teams
<br> Time: 10:00 a.m. - 11 a.m. ET, Thursday, 10/30/2025
<br>Speaker: [Brett Meeks](https://www.kimbell-associates.com/brett-meeks.html)

|         |
| ------- |
| <img src="https://www.kimbell-associates.com/uploads/1/1/0/7/110790979/7l5a7983-2_orig.jpg" width="300" /> |
| Brett Meeks <br> Vice President of Government Affairs, Health Technology and AI <br>Jeffrey J. Kimbell & Associates |

**Abstract**
Brett Meeks will review current activities and discussion around the regulation of artificial intelligence (AI) by the federal government, with a particular focus on the use of AI tools in health care. The presentation will include a review of the Trump Administration’s AI Action Plan and proposed legislation in congress related to AI.

**Bio**
Brett Meeks is Vice President of Government Affairs, Health Technology and AI at Jeffrey J. Kimbell & Associates, a boutique health care lobbying firm based in Washington, DC. Brett represents clients and coalitions working to improve the delivery of health care through technology and innovation. Brett served as the Executive Director of the Health Innovation Alliance, a coalition focused on improving health care with technology and data. He has also worked for the Center for Medical Interoperability, a non-profit research lab in Nashville seeking to connect medical devices and other technologies through a common platform to improve care. Prior to moving to Nashville, Brett served as Deputy Health Policy Director on the Senate Committee on Health, Education, Labor and Pensions for Chairman Lamar Alexander of Tennessee where he wrote, negotiated, and oversaw passage of several federal health care laws, including the 21st Century Cures Act. He has over eight years of experience in the U.S. Senate and has also spent time working in a wide range of health care law and policy positions, including a small physician practice, a large research hospital, a small litigation firm, and a health policy consultancy. Brett is a graduate of the University of Virginia, the National Defense University, and the University of Mississippi School of Law. He lives in Nashville with his wife and two daughters.

<a href="#top"> &#10558; Back to top</a>

---

# Schedule

<!---
The table should be update routein to reflect the upcoming events, and the past events should be at the bottom of the table.
-->

Please reach out if you are interested in presenting at a future event

|      Date      |    Location    |        Name            |          Affilication           |      Talk      |
| :------------: | :------------: | :--------------------: | :-----------------------------: | :------------: |
| 01-09-2025 | Virtual | Fernanda Foertter | ORNL | Problems with preparing data for AI workloads |
| 01-23-2025 | On Site | Bowen Jing | Massachusetts Institute of Technology | Denoising Generative Modeling for Molecular Structures and Dynamics |
| 02-27-2025 | Virtual | Dong Li | University of California, Merced | Learned Tensor-Offloading: GPU Memory-Efficient Execution Paradigm for Large Deep-Learning Models |
| 04-03-2025 | On Site | Ayush Chopra | Massachusetts Institute of Technology | What can we learn from a billion agents? |
| 05-15-2025 | Virtual | Justin Smith| NVIDIA | Efficiency and Accuracy Challenges in AI-Driven Atomistic Simulation |
| 06-26-2025 | On Site | Christopher Sutton | University of South Carolina | Accelerating Materials Discovery with AI |
| 09-18-2025 | On Site | Yongqiang Cheng | ORNL | AI-powered exploration of vibrational spectroscopy and materials discovery |
| 09-25-2025 | Virtual | Nando Fioretto | University of Virginia | Constraint-Aware Diffusion Models for Reliable Scientific Design |
| 10-02-2025 | On Site | Dayton Kizzire| ORNL | XsymNet, a framework for coupling deep learning and crystallographic group-theoretical methods |
| 10-30-2025 | Virtual | Brett Meeks | Jeffrey J. Kimbell & Associates | Federal AI Policy Overview |
| 11-20-2025 | Virtual | Samy Wu Fung | Colorado School of Mines | Designing Explainable Neural Networks with Physics Constraints via Optimization |

<a href="#top"> &#10558; Back to top</a>

# Past Presentations

---

**XsymNet: Combined Exhaustive Symmetry and Machine Learning for Phase Transition Studies**

<br>Location: room F234 bldg 5700 and MS Teams
<br> Time: 11:00 a.m. - 12 p.m. ET, Thursday, 10/02/2025
<br>Speaker: [Dayton Kizzire](https://www.ornl.gov/staff-profile/dayton-kizzire)

|         |
| ------- |
| <img src="https://www.ornl.gov/sites/default/files/styles/staff_profile_image_style/public/2025-06/Dayton%20profile%20picture_1.jpeg?h=1cc6dd60&itok=FU36OSHb" width="200" /> |
| Dayton Kizzire <br> Neutron Scattering Postdoc <br>Spallation Neutron Source, ORNL |

**Abstract**
Determining the atomic structure of materials along the phase transition pathway using either neutron or x-ray powder diffraction is typically a labor-intensive process of iterative structural design and refinement that requires expert domain knowledge. Such bottom-up approaches either do not fully leverage the existing knowledge within the problem domain or are overly tailored to specific systems thus compromising the generalizability and present a major bottleneck for high throughput analysis. Here we present a top-down deep learning approach for structure determination by combining group-theoretical methods for an exhaustive list of symmetry candidates and a multi-head attention convolutional neural network for classification. The developed workflow, termed XsymNet, is demonstrated to reliably identify the structure (including space group type, lattice, and atomic positions) along the displacive phase transition pathway for several representative systems with both simple and complex phase diagrams. Both high-resolution neutron and X-ray powder diffraction data have shown to work robustly with XsymNet for structure identification. Our work highlights the power of combining physics domain knowledge with the non-linearity of neural networks to solve complex phase diagrams, and further, this framework is readily extendable for use with single crystal and diffuse scattering experiments.

**Bio**
Dayton Kizzire is a neutron scattering postdoc in the powder diffraction group of the Neutron Scattering Division (NSD) at Oak Ridge National Laboratory (ORNL). His research focuses on structure-property relationships and combining AI/ML and neutron scattering for atomic level structural studies for functional materials. His recent work includes the development of the XsymNet framework, which combines crystallographic group-theoretical methods, deep learning, and neutron/X-ray scattering to solve complicated phase transitions. Dayton is a member of the American Crystallographic Association (ACA) and is currently serving as the representative for neutron scattering postdocs at the Spallation Neutron Source (SNS). 

---

**Constraint-Aware Diffusion Models for Reliable Scientific Design**

<br>Location: MS Teams
<br> Time: 10:00 a.m. - 11 a.m. ET, Thursday, 09/25/2025
<br>Speaker: [Ferdinando (Nando) Fioretto](https://nandofioretto.github.io/), 

|         |
| ------- |
| <img src="https://nandofioretto.github.io/assets/img/head_syr.png" width="200" /> |
| Ferdinando Fioretto<br> Assistant Professor of Computer Science <br>University of Virginia |

**Abstract**
Generative artificial intelligence (AI) has recently attracted significant attention for its potential to accelerate a broad range of scientific and engineering domains.  However, while these models produce statistically plausible outputs, they often fail to adhere to physical principles, conservation laws, or safety constraints.  Such violations result in suggested designs that may be impractical, unstable, or even hazardous.  This talk presents our current efforts to address these challenges by introducing a new class of training-free, constraint-aware diffusion models that integrate differentiable optimization techniques with generative modeling.  We will review the mathematical foundations for incorporating both static and dynamic constraints into diffusion models, extend these results for the case of discrete diffusion models, and present case studies of inverse design in microstructural materials, protein-pocket design, multi-robot motion planning, and synthetic chemistry. 

**Bio**
Ferdinando (Nando) Fioretto is an assistant professor of Computer Science at the University of Virginia.  His research focuses on addressing foundational challenges to advance AI, privacy, fairness, and the intersection between machine learning and optimization.  In particular, his group focuses on two key questions: (1) How to endow discriminative and generative machine learning (ML) models the ability to comply with constraints, uphold physical principles, and adhere to safety standards, and (2) How to ensure that ML models and decision-making systems adhere to safety, privacy, and fairness principles.  While the focus of his research is foundational, Nando’s research is motivated by the application of ML in science and engineering, with applications to power systems, material science, policy optimization, and beyond.
 
His work has been recognized with the 2022 Caspar Bowden Award for Outstanding Research in Privacy Enhancing Technologies, the International Joint Conference on Artificial Intelligence 22 Early Career spotlight, the 2017 AI*AI Best AI dissertation award, and several best paper awards.  Nando is also a recipient of the National Science Foundation Early Career Development Program award, the Google Research Scholar Award, the Amazon Research Award, the Italian Scientists and Scholars in North America Foundation Mario Gerla Young Investigator Award, and the Association for Constraint Programming Early Career Researcher Award in Constraint Programming.  He is a board member of the Artificial Intelligence Journal and has been a member of the organizing committee of several workshops, tutorials, and events with focus on privacy, fairness, and optimization at premier AI and ML venues.
 
He holds a dual Ph.D. in Computer Science from the University of Udine and the New Mexico State University.  Before joining the University of Virginia, Nando was an assistant professor at Syracuse University, a postdoctoral research associate at the Georgia Institute of Technology, and a research fellow at the University of Michigan.

---

**AI-powered exploration of vibrational spectroscopy and materials discovery**

<br>Location: room F234 bldg 5700 and MS Teams
<br> Time: 11:00 a.m. - 12 p.m. ET, Thursday, 09/18/2025
<br>Speaker: [Yongqiang Cheng](https://www.ornl.gov/staff-profile/yongqiang-cheng)

|         |
| ------- |
| <img src="https://www.ornl.gov/sites/default/files/styles/staff_profile_image_style/public/2021-10/Portrait%20-%20Yongqiang%20%28YQ%29%20Chen-102_sm.jpg?h=54b851a1&itok=m3ehEFgQ" width="200" /> |
| Yongqiang Cheng <br>Senior Staff Scientist <br>ORNL |

**Abstract**
Atomic vibrations are fundamental processes in materials and serve as sensitive indicators of their properties. These vibrations can be probed through a variety of spectroscopic techniques employing photons, electrons, or neutrons. However, interpreting spectral data and linking specific features to atomistic mechanisms, material properties, and fundamental insights remain significant challenges. In this presentation, I will highlight recent advances in applying AI and machine learning to accelerate and enrich spectral analysis. I will compare several methodological approaches, outlining their advantages, limitations, and underlying algorithms. The broader implications of these techniques for the future of vibrational spectroscopy will also be discussed. Finally, I will demonstrate how vibrational and thermal properties can be harnessed to guide generative models for targeted materials discovery and design.

**Bio**
Yongqiang Cheng obtained his PhD from Johns Hopkins University and joined the ORNL in 2011 as a Shull Fellow. He later continued at ORNL as a neutron scattering scientist specializing in spectroscopy. His current research focuses on integrating atomistic modeling, neutron scattering, and advanced data analysis techniques, including machine learning, to uncover and predict fundamental processes in materials.

---

**Accelerating Materials Discovery with AI**

<br>Location: room TBD and MS Teams
<br> Time: 11:00 a.m. - 12 p.m. ET, Thursday, 06/26/2025
<br>Speaker: [Christopher Sutton](https://www.suttonlabsc.com/about-me)

|         |
| ------- |
| <img src="https://sc.edu/study/colleges_schools/chemistry_and_biochemistry/images/staff_photos/sutton_christopher/sutton_christopher.jpg" width="200" /> |
| Christopher A. Sutton<br>Assistant Professor <br>University of South Carolina|

**Abstract**

Advances in materials science that drive technological innovation depend on a quantitative under-
standing of atomic-scale phenomena and the chemical and physical processes they govern. Moreover,
the predictive design of new materials for targeted applications requires identifying stable compositions
and their corresponding crystal structures with ideal properties. Thus, a major hurdle in computational
materials science is the development of robust structural models and accurate electronic structure pre-
dictions that reliably connect theoretical calculations with experimental observations.

In this talk, I will highlight recent advances in applying quantum mechanics (QM) and machine
learning (ML) to discover new materials and model their properties, with the goal of accelerating inno-
vative materials design for energy storage and generation. I will present our work using machine learning
interatomic potentials to predict the structures of new materials (such as hybrid organic soft-lattice semi-
conductors) and to provide atomistic insights into complex systems (such as novel anode materials for
Li-ion batteries). In addition, generative models for materials discovery have recently shown promise in
producing realistic crystal and molecular structures from random noise. I will discuss our recent efforts
to use generative models to identify transition states and reaction pathways in heterogeneous catalysis,
offering a potential alternative to the long-standing nudged elastic band (NEB) method. Finally, I will
highlight how ML can circumvent costly electronic structure calculations by providing high-fidelity band
structures, thereby improving our computational understanding of a material’s electronic properties.

**Speaker Bio**

Chris Sutton completed his PhD from Georgia Tech under the supervision of Jean-Luc Bredas. Afterwards, he did a brief postdoc with Weitao Yang at Duke University working on high fidelity eletronic structure methods. In 2015, he joined the Fritz-Haber Institute in Berlin as an Alexander von Humboldt postdoctoral fellow . In 2021, Chris joined the Chemistry/Biochemistry Department at the University of South Carolina. His research primarily focuses on combining computation and machine learning  to accelerate materials discovery.

---

**Efficiency and Accuracy Challenges in AI-Driven Atomistic Simulation**

<br>Location: Virtual on MS Teams
<br> Time: 11:00 a.m. - 12 p.m. ET, Thursday, 05/15/2025
<br>Speaker: [Justin S. Smith](https://developer.nvidia.com/blog/author/jusmith/)

|         |
| ------- |
| <img src="https://developer-blogs.nvidia.com/wp-content/uploads/2024/11/cropped-justin-smith-540x540.jpg" width="270" /> |
| Justin S. Smith, Ph.D.<br>Senior Developer Relations Manager <br>NVIDIA |

**Abstract**

This presentation delves into advancements and challenges in atomistic simulation for chemistry and materials science, focusing on three key themes. First, we explore batching techniques to improve simulation efficiency for high-throughput atomistic modeling. Second, we discuss issues in scaling Graph Neural Network (GNN)-based atomistic machine learning models for large-scale simulations, examining limitations and potential solutions. Third, we address the impact of training data selection and targets on improving model accuracy. By covering these topics, this presentation aims to provide an overview of our recent publications and the status of software tools development for AI-driven atomistic simulation, offering valuable insights and future directions for researchers and practitioners.

**Speaker Bio**

Dr. Justin S. Smith, Ph.D. in computational chemistry from the University of Florida, is known for his pioneering work in the development of machine learning interatomic potentials (MLIPs). As a primary developer of the ANI class of MLIPs, Justin has significantly advanced the field of computational chemistry by creating models that accurately predict molecular properties and dynamics. In addition to his work on the ANI class of models, Justin contributed to the development of the AIMNet and HIP-NN family of models. His efforts in these areas have focused on improving the accuracy and efficiency of MLIPs, enabling more precise simulations of molecular systems. Justin has also been instrumental in advancing active learning techniques for robust dataset generation, which are crucial for training accurate and transferable MLIPs. In recent years, Justin has been managing NVIDIA's strategy in the AI for chemistry and materials science domain. In this role, he has been responsible for overseeing partnerships, prioritization, development and deployment relating to AI-driven tools and technologies that are transforming molecular and materials simulation across domains.

---

**What can we learn from a billion agents?**

<br>Location:Building 5700, Room F234
<br> Time: 10:00 a.m. - 11 p.m. ET, Thursday, 04/03/2025
<br>Speaker: Ayush Chopra

**Abstract**

From pandemic response to supply chain resilience, today's critical challenges emerge from the complex interactions of millions of autonomous agents.  Traditional agent-based simulations struggle to scale beyond small populations while preserving rich agent behaviors and interaction patterns, making it difficult to model these societal-scale phenomena.  This talk introduces Large Population Models (LPMs), a novel methodology that enables high-performance, privacy-preserving modeling of massive agent populations.
 
LPMs enable societal-scale modeling through three key innovations.  First, they scale to millions of synthetic agents while preserving rich agent behaviors—from simple heuristics to language model-powered interactions—achieving unprecedented efficiency: simulating 8M agents in 5 minutes versus 50 hours in traditional approaches.  Second, LPMs maintain end-to-end differentiability of the simulation dynamics, enabling use of gradients to automatically calibrate against heterogeneous real-world data sources, compose with neural networks and perform rapid sensitivity analysis without repeated simulation—accelerating model tuning by 8300×.  Third, LPMs bridge simulation and reality through secure multi-party computation, enabling real-world agents to participate in decentralized simulations while preserving the privacy of their states and interactions - effectively “backpropagating through reality”.
 
These capabilities are unified in AgentTorch, our open-source framework for composable agent simulation at scale.  We demonstrate AgentTorch's impact through high-stakes applications: optimizing vaccine distribution across populations of 5+ million, safeguarding billion-dollar food supply chains, and modeling disease spread in dense urban environments of 8+ million residents.  As we scale towards a world with billions of agents, LPMs establish a foundation for next-generation high-performance computing platforms that can help address national-scale challenges while preserving data privacy and security.

**Bio**

Ayush Chopra is a PhD student at Massachusetts Institute of Technology (MIT), where he lead research on Large Population Models (lpm.media.mit.edu) under Prof. Ramesh Raskar's supervision.  His work bridges theoretical advances in multi-agent artificial intelligence (AI) with real-world impact - reaching over 20 million people through deployments across multiple countries and garnering coverage in global press.  He has published over 50 papers in leading conferences and journals, including the international conference on Autonomous Agents and Multiagent Systems (AAMAS), the conference on Computer Vision and Pattern Recognition, Knowledge Discovery in Databases, British Medical Journal; earning best paper awards and contributing to 25 patents.  Ayush’s research experience spans academic and industry labs, including Mayo Clinic and JP Morgan AI Research.  Prior to MIT, he was a scientist at Adobe where he received the Outstanding Young Engineer Award for his work on collaborative machine learning. Ayush has co-organized workshops and tutorials on multi-agent systems at the International Conference on Learning Representations (2021, 2023) and AAMAS (2024).  He earned his MS from MIT and BE from Delhi College of Engineering.

---

**Learned Tensor-Offloading: GPU Memory-Efficient Execution Paradigm for Large Deep-Learning Models**

<br>Location: Virtual on MS Teams
<br> Time: 11:00 a.m. - 12 p.m. ET, Thursday, 02/27/2025
<br>Speaker: [Dong Li](https://faculty.ucmerced.edu/dong-li/)

|         |
| ------- |
| <img src="https://eecs.ucmerced.edu/sites/eecs.ucmerced.edu/files/li_dong_150223-3_0.jpg" /> |
| Dong Li <br>Associate Professor <br>Department of Electrical Engineering and Computer Science (EECS), University of California, Merced |

**Abstract**

Training and deploying large deep-learning (DL) models face a memory capacity problem because of increasing model size or limited GPU memory capacity. Tiered memory architectures based on heterogeneous GPU/CPU memories provide a cost-effective solution to enable large DL models on GPU with limited memory. However, using tiered memory faces challenges on tensor management because of the dynamic structure of DL models and irregular memory accesses patterns in the DL workloads. In this talk, we introduce a learned approach (using a neural network or NN) to increase predictability of tensor accesses and facilitate memory management on tiered memory. To make the learned approach feasible, we address a series of challenges for NN feature representation to capture DL memory access patterns, and NN overhead control without sacrificing the effectiveness of NN guidance. Using the learned approach, we largely outperform UVM and tensor materialization (two approaches to enable large DL models on GPU) by 3× and 2.1× respectively in terms of maximum batch size. In the scenarios of industrial-scale deep-learning recommendation model (DLRM), our approach effectively reduces end-to-end DLRM inference time by up to 43%, compared to LRU caching in production.

**Bio**

Dong Li is an associate professor at EECS, University of California, Merced. Previously, he was a research scientist at the Oak Ridge National Laboratory (ORNL), studying computer architecture and programming models for next generation supercomputer systems. Dong earned his PhD in computer science from Virginia Tech. His research focuses on high performance computing (HPC), and maintains a strong relevance to computer systems. The core theme of his research is to study how to enable scalable and efficient execution of enterprise and scientific applications on increasingly complex large-scale parallel systems. Dong received an ORNL/CSMD Distinguished Contributor Award in 2013, a CAREER Award from the National Science Foundation in 2016, Facebook faculty research award in 2021, Oracle Research Award in 2022, Western Digital Research Award in 2022. His paper in SC'14 was in the best paper final list. His paper in ASPLOS'21 won the distinguished artifact award. He was also the lead PI for the NVIDIA CUDA Research Center at UC Merced. He is an associate editor for IEEE Transactions on Parallel and Distributed Systems (TPDS).

---

**Denoising Generative Modeling for Molecular Structures and Dynamics**

<br>Location: Building 5700, room F234
<br> Time: 11:00 a.m. - 12 p.m. ET, Thursday, 01/23/2025
<br>Speaker: [Bowen Jing](https://people.csail.mit.edu/bjing/), Electrical Engineering and Computer Science, MIT

**Abstract**

The three-dimensional structure and dynamics of molecules yields crucial insights into their chemical properties and biological functions. In this talk, we will discuss how denoising generative modeling has provided a novel and powerful paradigm for the prediction and sampling of molecular structures and dynamics.  Our work is often guided by considerations of physical symmetry and constrained degrees of freedom, requiring extensions of well-known methods to non-Euclidean spaces which best describe molecular flexibility. We will first show how diffusion over torsional coordinates lays the groundwork for modeling small, druglike molecules. Second, we combine this framework with rigid body motions to learn molecular docking to protein structures. Third, we address conformational sampling of proteins and successfully emulate ensembles from molecular dynamics at reduced computational cost. Finally, we discuss video-like modeling of whole molecular dynamics trajectories, enabling multipurpose generative models trained on simulated data.

**Bio**

Bio: Bowen Jing is a 4th year Ph.D. candidate in Electrical Engineering and Computer Science at MIT, co-advised by Tommi Jaakkola and Bonnie Berger. He works on deep learning for structural biology and drug discovery, with a focus on generative models and molecular simulation. He is also a DOE Computational Science Graduate Fellow and completed a practicum in the X Computational Physics Division at at Los Alamos National Laboratory. 

---

**Problems with preparing data for AI workloads**

<br>Location: virtual (MS Teams)
<br> Time: 11:00 a.m. - 12 p.m. ET, Thursday, 01/09/2025
<br>Speaker: [Fernanda Foertter](https://impact.ornl.gov/en/persons/fernanda-foertter)

|         |
| ------- |
| <img src="https://foertter.com/wp-content/uploads/2023/01/22-1116oraclenvidia42921-edited.jpg" width="300" /> |
| Fernanda Foertter <br>Senior HPC Engineer <br>Computational Sciences and Engineering Division, ORNL |

**Abstract**

Preparing data for AI workloads is to put it mildly, awful. Foundational models are best with huge amounts of data but depending on the domain this task can very dramatically in difficulty. This talk will explore the complexities of data preparation for AI and will discuss common tools and methods used from several people surveyed and interviewed for this talk. This talk will also include a mini-workshop where all attendees can share preferred methods and tools with the goal of building community at ORNL.

**Bio**

Fernanda has been in the intersection of scientific computing data wraggling for 15 years. She has a background in physics and molecular dynamics but later transitioned into genomics and healthcare data. Fernanda was at ORNL previously and worked on CORAL and ECP projects and led the training efforts to migrate applications from CPU to GPU on Titan and Summit. After 6 years in industry Fernanda recently returned to ORNL to continue contributing to the mission of the lab and is currently a member of the Scalable Biomedical Simulation group working on MOSSAIC. She has a penchant for building communities of practice and hopes to build one that helps improve how we do data engineering.


<a href="#top"> &#10558; Back to top</a>

# Organization

For questions, please contact us.
<style>
td, th {
   border: none!important;
}
</style>

|                |                |                |                |
| -------------- | -------------- | -------------- | -------------- |
| [![Yan Liu](https://www.ornl.gov/sites/default/files/styles/staff_profile_image_style/public/2019-04/liuy8.png?h=5114cd9b&itok=5Nt4keCd)](https://www.ornl.gov/staff-profile/yan-liu) | [![Jong Youl Choi](https://www.ornl.gov/sites/default/files/styles/staff_profile_image_style/public/2021-02/jychoi2_0.png?h=273942d0&itok=wF9lLEZU)](https://www.ornl.gov/staff-profile/jong-youl-choi) | [![Chen Zhang](https://www.ornl.gov/sites/default/files/styles/staff_profile_image_style/public/2020-10/profile_0.png?h=c49a1206&itok=ntQg6NeU)](https://www.ornl.gov/staff-profile/chen-zhang) | [![Prasanna Balaprakash](https://www.ornl.gov/sites/default/files/styles/staff_profile_image_style/public/2023-03/BalaprakashProfile_0.jpg?h=17644140&itok=AYUSlKCG)](https://www.ornl.gov/staff-profile/prasanna-balaprakash) |
| Yan Liu <br> Computational Scientist <br> Computational Sciences & Engineering Division <br> ORNL | Jong Youl Choi <br> HPC Data Research Scientist <br> Computer Science and Mathematics Division <br> ORNL | Chen Zhang <br> Computational Scientist <br> Computer Science and Mathematics Division <br> ORNL | Prasanna Balaprakash<br> Director of AI Programs <br> Distinguished R&D Staff Scientist<br> Computing and Computational Sciences Directorate, ORNL |

<a href="#top"> &#10558; Back to top</a>
